# ğŸ† MyTwin Leaderboard

SystÃ¨me automatisÃ© d'Ã©valuation et de rÃ©compense des contributions dÃ©veloppeurs pour des challenges de dÃ©veloppement. Le systÃ¨me identifie, Ã©value et attribue automatiquement des points de contribution basÃ©s sur l'analyse IA des commits, du code et des documents.

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [FonctionnalitÃ©s](#fonctionnalitÃ©s)
- [Installation](#installation)
- [Configuration](#configuration)
- [Utilisation](#utilisation)
- [Structure du projet](#structure-du-projet)
- [Packages](#packages)

## ğŸ¯ Vue d'ensemble

**MyTwin Leaderboard** est une plateforme qui automatise l'Ã©valuation des contributions dÃ©veloppeurs dans le cadre de challenges de dÃ©veloppement. Le systÃ¨me :

- ğŸ”Œ **Se connecte** Ã  des services externes (GitHub, Google Drive, etc.)
- ğŸ¤– **Identifie automatiquement** les contributions pertinentes via des agents IA
- ğŸ“Š **Ã‰value** chaque contribution selon des grilles de critÃ¨res personnalisables
- ğŸ’° **Distribue** des rÃ©compenses (Contribution Points) proportionnellement aux scores
- ğŸ“ˆ **Maintient** un leaderboard en temps rÃ©el

### Cas d'usage

Le systÃ¨me est conÃ§u pour gÃ©rer des **challenges** (sprints de dÃ©veloppement) oÃ¹ :

1. Une Ã©quipe travaille sur un projet avec des repositories GitHub
2. Des rÃ©unions de synchronisation sont documentÃ©es dans Google Drive
3. Le systÃ¨me analyse automatiquement les commits et identifie les contributions
4. Chaque contribution est Ã©valuÃ©e selon des critÃ¨res (qualitÃ©, impact, complexitÃ©, etc.)
5. Ã€ la fin du challenge, les rÃ©compenses sont distribuÃ©es proportionnellement

## ğŸ—ï¸ Architecture

Le projet est organisÃ© en **packages monorepo** avec une sÃ©paration claire des responsabilitÃ©s :

```
leaderboard/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ connectors/          # Connecteurs externes (GitHub, Google Drive)
â”‚   â”œâ”€â”€ database-service/     # Service de base de donnÃ©es PostgreSQL
â”‚   â”œâ”€â”€ evaluator/           # SystÃ¨me d'Ã©valuation IA
â”‚   â”œâ”€â”€ services/             # Services d'orchestration
â”‚   â””â”€â”€ test/                 # Scripts de test
â””â”€â”€ challenges/               # SpÃ©cifications des challenges
```

### Flux de donnÃ©es

```
1. Challenge Service
   â†“
2. Connectors (GitHub, Google Drive)
   â†“
3. Evaluator (Agents IA)
   â†“
4. Database Service
   â†“
5. Leaderboard
```

## âœ¨ FonctionnalitÃ©s

### ğŸ”Œ Connecteurs externes

- **GitHub** : RÃ©cupÃ©ration des commits et contenu des fichiers modifiÃ©s
- **Google Drive** : Extraction des documents de synchronisation (Sync summaries)
- **Extensible** : Architecture permettant d'ajouter facilement de nouveaux connecteurs (HuggingFace, Slack, etc.)

### ğŸ¤– Ã‰valuation automatisÃ©e

- **Identification** : Agent IA qui identifie les contributions Ã  partir des commits et rÃ©unions
- **Ã‰valuation** : Agent IA qui Ã©value chaque contribution selon des grilles de critÃ¨res
- **Grilles personnalisables** : CritÃ¨res et poids ajustables par type (code, model, dataset, docs)
- **Tool calling** : L'agent peut lire des fichiers pour analyser le code en profondeur

### ğŸ’¾ Base de donnÃ©es

- **PostgreSQL** avec **Drizzle ORM**
- **Validation Zod** pour toutes les entrÃ©es
- **Repositories** avec mÃ©thodes CRUD et requÃªtes spÃ©cialisÃ©es
- **Relations** configurÃ©es pour des jointures optimisÃ©es

### ğŸ’° SystÃ¨me de rÃ©compenses

- **Distribution proportionnelle** : Les Contribution Points sont distribuÃ©s selon les scores
- **Pool de rÃ©compenses** : Chaque challenge a un pool de points Ã  distribuer
- **Calcul automatique** : Les rÃ©compenses sont calculÃ©es Ã  la fin du challenge

## ğŸš€ Installation

### PrÃ©requis

- **Node.js** >= 18.x
- **PostgreSQL** >= 14.x
- **npm** ou **yarn**

### Ã‰tapes d'installation

1. **Cloner le repository**

```bash
git clone <repository-url>
cd leaderboard
```

2. **Installer les dÃ©pendances**

```bash
npm install
# ou
yarn install
```

3. **Configurer la base de donnÃ©es**

CrÃ©ez une base de donnÃ©es PostgreSQL :

```sql
CREATE DATABASE mytwin_leaderboard;
```

4. **Configurer les variables d'environnement**

CrÃ©ez un fichier `.env` Ã  la racine du projet :

```env
# Base de donnÃ©es
DATABASE_URL=postgresql://user:password@localhost:5432/mytwin_leaderboard

# OpenAI (pour l'Ã©valuateur)
OPENAI_API_KEY=sk-...

# GitHub (pour les connecteurs)
GITHUB_TOKEN=ghp_xxxxx
GITHUB_OWNER=your-org

# Google Drive (pour les connecteurs)
GOOGLE_CLIENT_ID=xxx.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=GOCSPX-xxxxx
GOOGLE_REFRESH_TOKEN=1//xxxxx
GOOGLE_REDIRECT_URI=http://localhost:3000/oauth/callback
GOOGLE_FOLDER_ID=your-folder-id
```

5. **Initialiser la base de donnÃ©es**

Les schÃ©mas Drizzle sont dÃ©finis dans `packages/database-service/db/drizzle.ts`. Vous devrez exÃ©cuter les migrations pour crÃ©er les tables.

## âš™ï¸ Configuration

### Variables d'environnement requises

| Variable               | Description                                   | Exemple                                    |
| ---------------------- | --------------------------------------------- | ------------------------------------------ |
| `DATABASE_URL`         | URL de connexion PostgreSQL                   | `postgresql://user:pass@localhost:5432/db` |
| `OPENAI_API_KEY`       | ClÃ© API OpenAI pour l'Ã©valuateur              | `sk-...`                                   |
| `GITHUB_TOKEN`         | Personal Access Token GitHub                  | `ghp_xxxxx`                                |
| `GITHUB_OWNER`         | PropriÃ©taire/organisation GitHub              | `facebook`                                 |
| `GOOGLE_CLIENT_ID`     | Client ID OAuth2 Google                       | `xxx.apps.googleusercontent.com`           |
| `GOOGLE_CLIENT_SECRET` | Client Secret OAuth2 Google                   | `GOCSPX-xxxxx`                             |
| `GOOGLE_REFRESH_TOKEN` | Refresh Token Google                          | `1//xxxxx`                                 |
| `GOOGLE_FOLDER_ID`     | ID du dossier Google Drive contenant les Sync | `1ABC...XYZ`                               |

### Configuration des connecteurs

Les connecteurs sont crÃ©Ã©s dynamiquement via le `ConnectorRegistry` basÃ© sur les repos enregistrÃ©s en base de donnÃ©es. Chaque repo doit avoir un `type` (github, google_drive, etc.) et les credentials correspondants dans les variables d'environnement.

## ğŸ“– Utilisation

### Exemple : Lancer une Ã©valuation de synchronisation

```typescript
import { ChallengeService } from "./packages/services/challenge.service.js";

const service = new ChallengeService();

// Lancer une Ã©valuation pour un challenge
const challengeId = "your-challenge-uuid";
const evaluations = await service.runSyncEvaluation(challengeId);

console.log(`${evaluations.length} contributions Ã©valuÃ©es`);
```

### Exemple : Calculer les rÃ©compenses

```typescript
// Ã€ la fin d'un challenge
const rewards = await service.computeChallengeRewards(challengeId);

rewards.forEach((reward) => {
  console.log(`${reward.contributionTitle}: ${reward.reward} CP`);
});
```

### Utilisation des packages individuellement

#### Connecteurs

```typescript
import { GitHubExternalConnector } from "./packages/connectors/implementation/Github.connector.js";

const connector = new GitHubExternalConnector({
  token: process.env.GITHUB_TOKEN,
  owner: "facebook",
  repo: "react",
});

await connector.connect();
const commits = await connector.fetchItems({ maxCommits: 50 });
const content = await connector.fetchItemContent(commits[0].id);
```

#### Database Service

```typescript
import {
  ProjectRepository,
  UserRepository,
} from "./packages/database-service/repositories/index.js";

const projectRepo = new ProjectRepository();
const project = await projectRepo.create({
  title: "MyTwin AI",
  description: "Projet de leaderboard IA",
});
```

#### Evaluator

```typescript
import { OpenAIAgentEvaluator, EvaluationGridRegistry } from "./packages/evaluator/index.js";

const evaluator = new OpenAIAgentEvaluator();

// Identifier les contributions
const contributions = await evaluator.identify({
  syncPreview: "...",
  commits: [...],
  users: [...]
});

// Ã‰valuer une contribution
const grid = EvaluationGridRegistry.getGrid("code");
const evaluation = await evaluator.evaluate(contribution, {
  snapshot: {...},
  grid
});
```

## ğŸ“ Structure du projet

```
leaderboard/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ connectors/
â”‚   â”‚   â”œâ”€â”€ interfaces.ts              # Interface ExternalConnector
â”‚   â”‚   â”œâ”€â”€ registry.ts                 # Factory pour crÃ©er des connecteurs
â”‚   â”‚   â”œâ”€â”€ connectors.orchestrator.ts  # Orchestration de plusieurs connecteurs
â”‚   â”‚   â”œâ”€â”€ implementation/
â”‚   â”‚   â”‚   â”œâ”€â”€ Github.connector.ts     # Connecteur GitHub
â”‚   â”‚   â”‚   â””â”€â”€ GD.connector.ts         # Connecteur Google Drive
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ database-service/
â”‚   â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”‚   â”œâ”€â”€ drizzle.ts              # SchÃ©mas Drizzle + Client DB
â”‚   â”‚   â”‚   â””â”€â”€ mappers.ts              # Conversions DB â†” Domain
â”‚   â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”‚   â”œâ”€â”€ entities.ts             # EntitÃ©s mÃ©tier TypeScript
â”‚   â”‚   â”‚   â””â”€â”€ schemas_zod.ts          # Validation Zod
â”‚   â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â”‚   â”œâ”€â”€ *.repo.ts               # Repositories CRUD
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluator/
â”‚   â”‚   â”œâ”€â”€ evaluator.ts                # OpenAIAgentEvaluator
â”‚   â”‚   â”œâ”€â”€ interfaces.ts               # Interface AgentEvaluator
â”‚   â”‚   â”œâ”€â”€ types.ts                    # Types de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ reward.ts                   # Calcul des rÃ©compenses
â”‚   â”‚   â”œâ”€â”€ grids/
â”‚   â”‚   â”‚   â”œâ”€â”€ code.grid.ts            # Grille d'Ã©valuation code
â”‚   â”‚   â”‚   â”œâ”€â”€ model.grid.ts           # Grille d'Ã©valuation modÃ¨les
â”‚   â”‚   â”‚   â”œâ”€â”€ dataset.grid.ts         # Grille d'Ã©valuation datasets
â”‚   â”‚   â”‚   â”œâ”€â”€ docs.grid.ts            # Grille d'Ã©valuation docs
â”‚   â”‚   â”‚   â””â”€â”€ index.ts
â”‚   â”‚   â”œâ”€â”€ openai/
â”‚   â”‚   â”‚   â”œâ”€â”€ identify.agent.ts        # Agent d'identification
â”‚   â”‚   â”‚   â””â”€â”€ evaluate.agent.ts       # Agent d'Ã©valuation
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ challenge.service.ts        # Service d'orchestration principal
â”‚   â”‚
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ test-challenge-service.ts
â”‚       â”œâ”€â”€ test-github.ts
â”‚       â”œâ”€â”€ test-gd.ts
â”‚       â””â”€â”€ test-db-connection.ts
â”‚
â””â”€â”€ challenges/
    â”œâ”€â”€ challenge_001_leaderboard/
    â”œâ”€â”€ challenge_002_authentication/
    â””â”€â”€ challenge_003_collaboration_patterns/
```

## ğŸ“¦ Packages

### ğŸ”Œ `connectors`

Package de connecteurs externes pour interagir avec diffÃ©rentes plateformes.

**FonctionnalitÃ©s** :

- Interface unifiÃ©e `ExternalConnector`
- Connecteurs GitHub et Google Drive
- Orchestrateur pour gÃ©rer plusieurs connecteurs en parallÃ¨le
- Extensible pour de nouveaux connecteurs

**Documentation** : Voir `packages/connectors/README.md`

### ğŸ—„ï¸ `database-service`

Service de gestion de la base de donnÃ©es PostgreSQL avec Drizzle ORM.

**FonctionnalitÃ©s** :

- SchÃ©mas Drizzle pour toutes les entitÃ©s
- Repositories avec CRUD complet
- Validation Zod pour toutes les entrÃ©es
- Mappers bidirectionnels DB â†” Domain

**Documentation** : Voir `packages/database-service/README.md`

### ğŸ¤– `evaluator`

SystÃ¨me d'Ã©valuation automatisÃ© des contributions basÃ© sur des agents IA.

**FonctionnalitÃ©s** :

- Agents OpenAI pour identification et Ã©valuation
- Grilles d'Ã©valuation personnalisables par type
- Calcul de rÃ©compenses proportionnel
- Tool calling pour analyse approfondie du code

**Documentation** : Voir `packages/evaluator/README.md`

### ğŸ¯ `services`

Services d'orchestration de haut niveau.

**FonctionnalitÃ©s** :

- `ChallengeService` : Orchestration complÃ¨te du cycle de vie d'un challenge
- MÃ©thodes `runSyncEvaluation` et `computeChallengeRewards`

## ğŸ”„ Workflow d'un challenge

1. **CrÃ©ation du challenge** : Un challenge est crÃ©Ã© en base avec dates, Ã©quipe, repos associÃ©s
2. **Sync Meeting** :
   - RÃ©cupÃ©ration des commits depuis GitHub
   - RÃ©cupÃ©ration du rÃ©sumÃ© de rÃ©union depuis Google Drive
   - Identification des contributions par l'agent IA
   - Ã‰valuation de chaque contribution
   - Sauvegarde en base de donnÃ©es
3. **Fin du challenge** :
   - Calcul des rÃ©compenses proportionnelles
   - Mise Ã  jour des contributions avec les points attribuÃ©s
   - GÃ©nÃ©ration du leaderboard

## ğŸ§ª Tests

Des scripts de test sont disponibles dans `packages/test/` :

```bash
# Tester la connexion Ã  la base de donnÃ©es
npx tsx packages/test/test-db-connection.ts

# Tester les connecteurs
npx tsx packages/test/test-github.ts
npx tsx packages/test/test-gd.ts

# Tester le service de challenge
npx tsx packages/test/test-challenge-service.ts
```

## ğŸ” SÃ©curitÃ©

- **Ne jamais hardcoder** les tokens et credentials
- Utiliser des **variables d'environnement** pour tous les secrets
- Valider toutes les entrÃ©es avec **Zod**
- Respecter les **rate limits** des APIs externes

## ğŸš§ DÃ©veloppement

### Ajouter un nouveau connecteur

1. CrÃ©er une classe implÃ©mentant `ExternalConnector` dans `packages/connectors/implementation/`
2. Ajouter le type dans `ConnectorType`
3. ImplÃ©menter toutes les mÃ©thodes requises
4. Ajouter la logique de crÃ©ation dans `ConnectorRegistry`

### Ajouter une nouvelle grille d'Ã©valuation

1. CrÃ©er un fichier dans `packages/evaluator/grids/`
2. DÃ©finir les critÃ¨res et leurs poids
3. Enregistrer dans `EvaluationGridRegistry`

## ğŸ“ Licence

[Ã€ dÃ©finir]

## ğŸ‘¥ Ã‰quipe

- **Antoine** - Software Engineer - github:KaoDje
- **Alix** - Software Engineer - github:Akralan

---

Pour plus de dÃ©tails sur chaque package, consultez les README individuels dans chaque dossier `packages/*/README.md`.
